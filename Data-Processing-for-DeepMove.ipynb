{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "adfe99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5b4573c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yjmob1 = 'yjmob100k-dataset1.csv.gz' # dataset under normal scenes\n",
    "yjmob_df = pd.read_csv(yjmob1, compression='gzip').sort_values(by=['uid', 'd', 't'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1ee0d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "USED_DATA_SIZE = 200 # data used ~ num of uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2ed8d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all ids\n",
    "uids = yjmob_df['uid'].unique()\n",
    "\n",
    "# Select id\n",
    "rand_indicies = [random.randint(0, len(uids)) for _ in range(USED_DATA_SIZE)] \n",
    "selected_uids = [uid for uid in uids[rand_indicies]]\n",
    "\n",
    "# load data into pd df\n",
    "df = yjmob_df[yjmob_df['uid'].isin(selected_uids)]\n",
    "\n",
    "# Time\n",
    "# df['combined_t'] = df['d']*47+df['t']\n",
    "\n",
    "# Gird-Location\n",
    "# got killed\n",
    "# def spatial_token(x, y):\n",
    "#     return (x-1)+(y-1)*200\n",
    "# df['combined_xy'] = df.apply(lambda row: spatial_token(row['x'], row['y']), axis=1)\n",
    "\n",
    "# Sort values and retrieve only the values of the useful data\n",
    "df = df.sort_values(by=['uid'])[['uid', 't', 'x']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b223b65",
   "metadata": {},
   "source": [
    "```\n",
    "data_neural = {\n",
    "    'user1': {\n",
    "        'sessions': [(loc1, tim1), (loc2, tim2), ...],\n",
    "        'train': [0, 1, 2],\n",
    "        'test': [3, 4]\n",
    "    },\n",
    "    'user2': {\n",
    "        'sessions': [(loc1, tim1), (loc2, tim2), ...],\n",
    "        'train': [0, 1],\n",
    "        'test': [2]\n",
    "    },\n",
    "    ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5870e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split indices into train and test\n",
    "# 7-3 Train-Test split\n",
    "def split_indices(n, test_ratio=0.3):\n",
    "    indices = list(range(n))\n",
    "    test_size = int(n * test_ratio)\n",
    "    train_indices = indices[:-test_size] if test_size else indices\n",
    "    test_indices = indices[-test_size:] if test_size else []\n",
    "    return train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "87859351",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1bc0288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_neural = {}\n",
    "WINDOW_SIZE = 10\n",
    "\n",
    "index = 0\n",
    "\n",
    "for uid, group in df.groupby('uid'):\n",
    "    group = group.head(STEP_SIZE)\n",
    "    sessions = {}\n",
    "    for i in range(0, len(group), WINDOW_SIZE):\n",
    "        # Using min to avoid index out of range for the last window\n",
    "        sessions[i // WINDOW_SIZE] = list(zip( group['x'][i:i + WINDOW_SIZE], \n",
    "                                             group['t'][i:i + WINDOW_SIZE]))\n",
    "    \n",
    "    # Define the split indices\n",
    "    num_sessions = len(sessions)\n",
    "    train_cutoff = int(num_sessions * 0.7)\n",
    "    \n",
    "    train_keys = list(sessions.keys())[:train_cutoff]\n",
    "    test_keys = list(sessions.keys())[train_cutoff:]\n",
    "\n",
    "    data_neural[index] = {\n",
    "        'sessions': sessions,\n",
    "        'train': train_keys,\n",
    "        'test': test_keys\n",
    "    }\n",
    "    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd98ecc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(len(data_neural))\n",
    "# data_neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "feaa6415",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "89746518",
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_list = [int(i) for i in range(len(data_neural))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a43d3803",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['data_neural'] = data_neural\n",
    "output['uid_list'] = uid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b5300682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary to a pickle file\n",
    "import pickle\n",
    "\n",
    "with open('my_data_neural.pk', 'wb') as f:\n",
    "    pickle.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9e8ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
