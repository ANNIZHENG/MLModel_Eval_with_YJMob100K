{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b12072",
   "metadata": {},
   "source": [
    "# Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e78992ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_neural = \\\n",
    "{'train_loc': {1: 2, 2: 1, 3: 1, 4: 12, 5: 1, 6: 2, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 2, 25: 2, 26: 1, 27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1}, \n",
    "'explore': 0.15384615384615385, \n",
    "'train': [0, 1, 2, 3, 4], \n",
    "'entropy': 3.219290807235925, \n",
    "'rg': 0.03142983221874803, \n",
    "'sessions': {\n",
    "0: [[1, 30], [2, 45], [3, 46], [4, 14], [4, 16], [5, 20], [6, 23], [7, 0], [4, 13], [8, 20], [9, 21]], \n",
    "1: [[10, 40], [4, 14], [11, 14], [12, 22], [13, 20], [4, 24], [14, 43], [4, 14], [15, 17], [4, 18], [16, 21]], \n",
    "2: [[17, 22], [4, 14], [18, 18], [4, 18], [19, 24], [20, 27], [21, 27]], \n",
    "3: [[22, 19], [4, 17], [23, 25], [24, 40], [25, 0], [4, 19], [4, 14], [26, 22], [6, 23]], \n",
    "4: [[27, 24], [28, 25], [1, 26], [29, 46], [25, 24], [24, 40], [30, 43], [31, 44], [32, 46], [33, 2]], \n",
    "5: [[1, 27], [4, 17], [34, 21], [35, 22], [4, 13], [36, 2], [4, 13], [37, 19], [38, 20], [36, 2], [36, 26]], \n",
    "6: [[39, 45], [10, 47], [35, 45], [36, 3], [4, 13]]\n",
    "},\n",
    "'test': [5, 6],\n",
    "'valid_len': 14, \n",
    "'pred_len': 43}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382ae8cb-56c8-4a8f-806a-a18f3484a24f",
   "metadata": {},
   "source": [
    "# Load Data (New)\n",
    "**Vertical Split + No Sliding Window**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9b58830-2ede-4be9-ac05-b510936abff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_train = pd.read_csv('df_train_1k.csv')\n",
    "df_test  = pd.read_csv('df_test_1k.csv')\n",
    "\n",
    "all_uids = df_test['uid'].unique() # store all unique uids\n",
    "\n",
    "data_neural = {}\n",
    "train_keys = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "test_keys = [8,9]\n",
    "num_users = len(all_uids)\n",
    "# train_keys = [0, 1, 2, 3]\n",
    "# test_keys = [4, 5]\n",
    "# num_users = 100\n",
    "\n",
    "# load train data\n",
    "for id in range(num_users):\n",
    "    data_neural[id] = {}\n",
    "    data_neural[id]['sessions'] = {}\n",
    "    for i in range(0,len(train_keys)*10,10):\n",
    "        data_neural[id]['sessions'][train_keys[i//10]] = df_train[df_train['uid']==all_uids[id]].iloc[i:i+10][['combined_xy', 't']].to_numpy().tolist()\n",
    "    for i in range(0,len(test_keys)*10,10):\n",
    "        data_neural[id]['sessions'][test_keys[i//10]] = df_test[df_test['uid']==all_uids[id]].iloc[i:i+10][['combined_xy', 't']].to_numpy().tolist()\n",
    "    data_neural[id]['train'] = train_keys\n",
    "    data_neural[id]['test'] = test_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1113dea7-9934-4306-aebb-8d958f5b6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "output['data_neural'] = data_neural\n",
    "uid_list = [int(i) for i in range(len(output['data_neural']))]\n",
    "output['uid_list'] = uid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0accbd55-3153-46de-9720-47d4b03c4f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('DeepMove-master/data/my_data_neural.pk', 'wb') as f:\n",
    "    pickle.dump(output, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ea2b4",
   "metadata": {},
   "source": [
    "# Load Data (Old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc51c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# # 1k data\n",
    "df_train = pd.read_csv('df_train_1k.csv')\n",
    "df_test  = pd.read_csv('df_test_1k.csv')\n",
    "grouped_data_train = [group for _, group in df_train.groupby('uid')]\n",
    "grouped_data_test = [group for _, group in df_test.groupby('uid')]\n",
    "\n",
    "# Sliding window by 1 STEP\n",
    "STEP_SIZE = 12\n",
    "WINDOW_SIZE = 10\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, grouped_data):\n",
    "        self.data = []\n",
    "        for group in grouped_data:\n",
    "            if len(group) >= STEP_SIZE:\n",
    "                # get the first STEP_SIZE location and time data\n",
    "                xy = group['combined_xy'].values.tolist()[:STEP_SIZE]\n",
    "                t = group['t'].values.tolist()[:STEP_SIZE]\n",
    "                # slice the data into several sessions using moving window approach\n",
    "                self.data.extend([(xy[i:i+WINDOW_SIZE], t[i:i+WINDOW_SIZE])\n",
    "                                  for i in range(STEP_SIZE-WINDOW_SIZE+1)])\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        xy_window, t_window = self.data[idx]\n",
    "        inputs = torch.tensor(xy_window[:-1])        # input sequence of locations\n",
    "        labels = torch.tensor(xy_window[-1])         # desired predicted location\n",
    "        positions = torch.tensor(t_window[:-1])      # corresponding input locations' times\n",
    "        label_positions = torch.tensor(t_window[-1]) # corresponding predicted location's time\n",
    "        return inputs, labels, positions, label_positions\n",
    "\n",
    "# Sliding window by STEP_SIZE\n",
    "STEP_SIZE = 20\n",
    "WINDOW_SIZE = 10\n",
    "class TrajectoryDatasetTEST(Dataset):\n",
    "    def __init__(self, grouped_data):\n",
    "        self.data = []\n",
    "        for group in grouped_data:\n",
    "            if len(group) >= STEP_SIZE:\n",
    "                # get the first STEP_SIZE location and time data\n",
    "                xy = group['combined_xy'].values.tolist()[:STEP_SIZE]\n",
    "                t = group['t'].values.tolist()[:STEP_SIZE]\n",
    "                # slice the data into several sessions using moving window approach\n",
    "                self.data.extend([(xy[i:i+WINDOW_SIZE], t[i:i+WINDOW_SIZE])\n",
    "                                  for i in range(0, STEP_SIZE-WINDOW_SIZE+1, STEP_SIZE)])\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        xy_window, t_window = self.data[idx]\n",
    "        inputs = torch.tensor(xy_window[:-1])        # input sequence of locations\n",
    "        labels = torch.tensor(xy_window[-1])         # desired predicted location\n",
    "        positions = torch.tensor(t_window[:-1])      # corresponding input locations' times\n",
    "        label_positions = torch.tensor(t_window[-1]) # corresponding predicted location's time\n",
    "        return inputs, labels, positions, label_positions\n",
    "\n",
    "train_dataset = TrajectoryDataset(grouped_data_train)\n",
    "test_dataset  = TrajectoryDatasetTEST(grouped_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8205ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataneural(train_dataset, test_dataset):\n",
    "    train_keys = [2,3,4,5]\n",
    "    test_keys  = [0,1]\n",
    "    \n",
    "    data_neural = {}\n",
    "    data_neural_index = 0\n",
    "    \n",
    "    test_data = test_dataset.data\n",
    "    index = 0\n",
    "    for i in range(0, len(test_data), 2):\n",
    "        data_neural[index]={'sessions':{}}\n",
    "        data_neural[index]['sessions'][0]=[[location,time] for location,time in zip(test_data[i][0],test_data[i][1])]\n",
    "        data_neural[index]['sessions'][1]=[[location,time] for location,time in zip(test_data[i+1][0],test_data[i+1][1])]\n",
    "        data_neural[index]['train']=train_keys\n",
    "        data_neural[index]['test']=test_keys\n",
    "        index += 1\n",
    "    \n",
    "    train_data = train_dataset.data\n",
    "    index = 0\n",
    "    for i in range(0, len(train_data), 4):\n",
    "        data_neural[index]['sessions'][2]=[[location,time] for location,time in zip(train_data[i][0],train_data[i][1])]\n",
    "        data_neural[index]['sessions'][3]=[[location,time] for location,time in zip(train_data[i+1][0],train_data[i+1][1])]\n",
    "        data_neural[index]['sessions'][4]=[[location,time] for location,time in zip(train_data[i+2][0],train_data[i+2][1])]\n",
    "        data_neural[index]['sessions'][5]=[[location,time] for location,time in zip(train_data[i+3][0],train_data[i+3][1])]\n",
    "        index += 1\n",
    "        if (index == len(data_neural)):\n",
    "            break\n",
    "        \n",
    "    return data_neural\n",
    "data_neural = format_dataneural(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0efe4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataneural(train_dataset, test_dataset, n, m):\n",
    "    train_data = train_dataset.data\n",
    "    test_data = test_dataset.data\n",
    "    \n",
    "    data_neural = {}\n",
    "    index = 0\n",
    "    \n",
    "    num_iterations = len(test_data) // m\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        data_neural[index] = {'sessions': {}, 'train': [], 'test': []}\n",
    "        \n",
    "        # Test Data\n",
    "        for j in range(m):\n",
    "            test_index = i * m + j\n",
    "            if test_index < len(test_data):\n",
    "                data_neural[index]['sessions'][j] = [[location, time] for location, time in zip(test_data[test_index][0], test_data[test_index][1])]\n",
    "                data_neural[index]['test'].append(j)\n",
    "        \n",
    "        # Train Data\n",
    "        for j in range(n):\n",
    "            train_index = i * n + j\n",
    "            if train_index < len(train_data):\n",
    "                data_neural[index]['sessions'][m + j] = [[location, time] for location, time in zip(train_data[train_index][0], train_data[train_index][1])]\n",
    "                data_neural[index]['train'].append(m + j)\n",
    "        \n",
    "        index += 1\n",
    "    \n",
    "    # Handle any remaining train data\n",
    "    remaining_train_data = len(train_data) % n\n",
    "    if remaining_train_data > 0:\n",
    "        data_neural[index] = {'sessions': {}, 'train': [], 'test': []}\n",
    "        start_index = num_iterations * n\n",
    "        for j in range(remaining_train_data):\n",
    "            train_index = start_index + j\n",
    "            if train_index < len(train_data):\n",
    "                data_neural[index]['sessions'][j] = [[location, time] for location, time in zip(train_data[train_index][0], train_data[train_index][1])]\n",
    "                data_neural[index]['train'].append(j)\n",
    "    \n",
    "    return data_neural\n",
    "\n",
    "n = 4 # Number of train data\n",
    "m = 2 # Number of test data\n",
    "data_neural = format_dataneural(train_dataset, test_dataset, n, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcc012cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "output['data_neural'] = data_neural\n",
    "uid_list = [int(i) for i in range(len(output['data_neural']))]\n",
    "output['uid_list'] = uid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5300682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('DeepMove-master/data/my_data_neural.pk', 'wb') as f:\n",
    "    pickle.dump(output, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fc18e1",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49849f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_neural = format_dataneural(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "010d979e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_neural': {0: {'sessions': {0: [[22273, 5],\n",
       "     [22273, 8],\n",
       "     [22273, 11],\n",
       "     [22273, 12],\n",
       "     [22272, 15],\n",
       "     [22478, 16],\n",
       "     [15333, 17],\n",
       "     [15332, 18],\n",
       "     [15332, 36],\n",
       "     [15333, 37]],\n",
       "    1: [[15329, 0],\n",
       "     [15329, 1],\n",
       "     [14930, 2],\n",
       "     [15329, 3],\n",
       "     [15329, 4],\n",
       "     [15329, 5],\n",
       "     [15329, 8],\n",
       "     [14930, 10],\n",
       "     [15329, 11],\n",
       "     [15130, 12]],\n",
       "    2: [[26284, 27],\n",
       "     [26284, 32],\n",
       "     [26284, 35],\n",
       "     [26887, 36],\n",
       "     [26687, 39],\n",
       "     [27290, 40],\n",
       "     [27489, 42],\n",
       "     [27090, 43],\n",
       "     [27489, 44],\n",
       "     [27489, 45]],\n",
       "    3: [[26284, 32],\n",
       "     [26284, 35],\n",
       "     [26887, 36],\n",
       "     [26687, 39],\n",
       "     [27290, 40],\n",
       "     [27489, 42],\n",
       "     [27090, 43],\n",
       "     [27489, 44],\n",
       "     [27489, 45],\n",
       "     [27489, 46]],\n",
       "    4: [[26284, 35],\n",
       "     [26887, 36],\n",
       "     [26687, 39],\n",
       "     [27290, 40],\n",
       "     [27489, 42],\n",
       "     [27090, 43],\n",
       "     [27489, 44],\n",
       "     [27489, 45],\n",
       "     [27489, 46],\n",
       "     [27290, 47]],\n",
       "    5: [[26887, 36],\n",
       "     [26687, 39],\n",
       "     [27290, 40],\n",
       "     [27489, 42],\n",
       "     [27090, 43],\n",
       "     [27489, 44],\n",
       "     [27489, 45],\n",
       "     [27489, 46],\n",
       "     [27290, 47],\n",
       "     [27290, 0]]},\n",
       "   'train': [2, 3, 4, 5],\n",
       "   'test': [0, 1]}},\n",
       " 'uid_list': [0]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = {}\n",
    "output['data_neural'] = {0: data_neural[0]}\n",
    "output['uid_list'] = [0]\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "00b7c0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('DeepMove-master/data/my_data_neural.pk', 'wb') as f:\n",
    "    pickle.dump(output, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be556fc3",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1058b22c",
   "metadata": {},
   "source": [
    "100 users, for each user 4 training data 2 testing data, 4 gpu, 0 accuracy, 10 loss\n",
    "\n",
    "```\n",
    "[[6107], [6305], [4687], [278], [76], [76], [76], [77], [6107], [5905], [6305], [4687], [278], [76], [76], [76], [77], [6107], [5905], [6107], [4687], [278], [76], [76], [76], [77], [6107], [5905], [6107], [6307], [278], [76], [76], [76], [77], [6107], [5905], [6107], [6307], [6107], [23482], [23484], [23484], [23483], [23482], [23484], [23295], [23097], [23298], [26487], [25725], [25724], [25725], [25724], [25925], [26924], [26924], [26925], [26925]]\n",
    "[[13], [14], [15], [16], [22], [23], [24], [26], [27], [28], [14], [15], [16], [22], [23], [24], [26], [27], [28], [14], [15], [16], [22], [23], [24], [26], [27], [28], [14], [17], [16], [22], [23], [24], [26], [27], [28], [14], [17], [18], [11], [14], [19], [11], [12], [14], [20], [21], [22], [23], [10], [11], [12], [13], [17], [18], [19], [21], [22]]\n",
    "[25724, 25725, 25724, 25925, 26924, 26924, 26925, 26925, 26924]\n",
    "None\n",
    "4687\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
