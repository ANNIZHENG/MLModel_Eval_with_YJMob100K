{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f373776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea429f6",
   "metadata": {},
   "source": [
    "# Data-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffeb3033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/xp23lpqx4ndfxcvp3qj_bdgr0000gn/T/ipykernel_1061/3526287213.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['combined_t'] = df['d']*47+df['t']\n",
      "/var/folders/hx/xp23lpqx4ndfxcvp3qj_bdgr0000gn/T/ipykernel_1061/3526287213.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['combined_xy'] = df.apply(lambda row: spatial_token(row['x'], row['y']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "yjmob1 = 'yjmob100k-dataset1.csv.gz' # dataset under normal scenes\n",
    "yjmob_df = pd.read_csv(yjmob1, compression='gzip').sort_values(by=['uid', 'd', 't'], ignore_index=True)\n",
    "\n",
    "# Retrieve all ids\n",
    "uids = yjmob_df['uid'].unique()\n",
    "\n",
    "# Just to reduce memory space\n",
    "rand_indicies = [random.randint(0, len(uids)) for _ in range(200)] # only 200 data would be used\n",
    "selected_uids = [uid for uid in uids[rand_indicies]] # selected_uids = uids[:200]\n",
    "# selected_uids = uids[:200]\n",
    "\n",
    "df = yjmob_df[yjmob_df['uid'].isin(selected_uids)] \n",
    "\n",
    "# Time\n",
    "df['combined_t'] = df['d']*47+df['t']\n",
    "\n",
    "# Location\n",
    "def spatial_token(x, y):\n",
    "    return (x-1)+(y-1)*200\n",
    "df['combined_xy'] = df.apply(lambda row: spatial_token(row['x'], row['y']), axis=1)\n",
    "\n",
    "# Sort value\n",
    "df = df.sort_values(by=['uid', 'combined_t'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cf51e5",
   "metadata": {},
   "source": [
    "# Train-Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e00c4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7:3 split\n",
    "train_uids, test_uids = train_test_split(selected_uids, test_size=0.30, random_state=42)\n",
    "\n",
    "# Load training and testing data\n",
    "df_train = df[df['uid'].isin(train_uids)]\n",
    "df_test = df[df['uid'].isin(test_uids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d443c8",
   "metadata": {},
   "source": [
    "# Batching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b74717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "STEP_SIZE = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "268da3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences(data, data_t):\n",
    "    return torch.tensor(data[:STEP_SIZE]),torch.tensor(data[STEP_SIZE]),\\\n",
    "                torch.tensor(data_t[:STEP_SIZE]),torch.tensor(data_t[STEP_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8f9aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by uid\n",
    "grouped_data_train = df_train[['uid', 'combined_t', 'combined_xy']].groupby('uid')\n",
    "grouped_data_train = [group for _, group in df_train.groupby('uid')]\n",
    "grouped_data_test = df_test[['uid', 'combined_t', 'combined_xy']].groupby('uid')\n",
    "grouped_data_test = [group for _, group in df_test.groupby('uid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60f6a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, grouped_data):\n",
    "        self.data = grouped_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_for_uid = self.data[idx]\n",
    "        inputs, labels, positions, label_positions = generate_sequences(\n",
    "                                                         data_for_uid['combined_xy'].values.tolist(),\n",
    "                                                         data_for_uid['combined_t'].values.tolist())\n",
    "        return inputs, labels, positions, label_positions\n",
    "\n",
    "train_dataset = TrajectoryDataset(grouped_data_train)\n",
    "test_dataset = TrajectoryDataset(grouped_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2841afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Unzip all batch\n",
    "    inputs_batch, labels_batch, positions_batch, label_positions_batch = zip(*batch)\n",
    "    \n",
    "    # Pad the sequence with less length in a batch\n",
    "    inputs_padded = torch.nn.utils.rnn.pad_sequence(inputs_batch, padding_value=0.0, batch_first=True)\n",
    "    labels_padded = torch.tensor(np.array(labels_batch))\n",
    "    positions_padded = torch.nn.utils.rnn.pad_sequence(positions_batch, padding_value=0, batch_first=True)\n",
    "    label_positions_padded = torch.tensor(np.array(label_positions_batch))\n",
    "    \n",
    "    return inputs_padded, labels_padded, positions_padded, label_positions_padded\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bc73eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: torch.Size([50, 600])\n",
      "Desired Output Shape: torch.Size([50])\n",
      "Positional Data Shape: torch.Size([50, 600])\n",
      "Corresponding Positional Data Shape:  torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "for inputs, labels, positions, label_positions in test_dataloader:\n",
    "    print(\"Input Shape:\", inputs.shape) # torch.Size([50, 600])\n",
    "    print(\"Desired Output Shape:\", labels.shape) # torch.Size([50])\n",
    "    print(\"Positional Data Shape:\", positions.shape) # torch.Size([50, 600])\n",
    "    print(\"Corresponding Positional Data Shape: \", label_positions.shape) # torch.Size([50])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d2e207",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a08593",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eab1e6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_len, embedding_dim):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embedding_dim, 2) * (-np.log(10000.0) / embedding_dim))\n",
    "        pe = torch.zeros(max_len, 1, embedding_dim)\n",
    "        pe[:, 0, 0::2] = torch.sin(position.float() * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position.float() * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return x \n",
    "    \n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, nhead, \n",
    "                 num_encoder_layers, num_decoder_layers, dim_feedforward, max_len):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim)\n",
    "        self.pos_encoder = PositionalEncoding(max_len, embed_dim)\n",
    "        self.transformer = nn.Transformer(embed_dim, nhead, \n",
    "                                          num_encoder_layers, num_decoder_layers, dim_feedforward)\n",
    "        self.decoder = nn.Linear(embed_dim, input_dim)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src): # , src_mask\n",
    "        src = self.embedding(src) * math.sqrt(self.embedding.embedding_dim)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer(src, src) # , src_mask\n",
    "        output = self.decoder(output)\n",
    "        \n",
    "        # Select the output of the last timestep for each sequence in the batch\n",
    "        final_output = output[:, -1, :]  # [batch_size, feature_size]\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3832ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_square_subsequent_mask(sz):\n",
    "#     mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "#     mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "#     return mask\n",
    "\n",
    "# Model Initialization\n",
    "input_dim = 200*200\n",
    "embed_dim = 64 \n",
    "nhead = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dim_feedforward = 4\n",
    "max_len = 3600\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TransformerModel(input_dim, embed_dim, nhead, \n",
    "                         num_encoder_layers, num_decoder_layers, dim_feedforward, max_len)\n",
    "\n",
    "# Training Preparation\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Mask for src\n",
    "# src_mask = generate_square_subsequent_mask(STEP_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37cd641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Average Loss 10.570607821146647\n",
      "CPU times: user 31.2 s, sys: 1min 16s, total: 1min 48s\n",
      "Wall time: 29.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "# Training\n",
    "epochs = 80\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels, positions, label_positions in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass: Model outputs the logits for the predicted location\n",
    "        # Output shape: [batch_size, grid_size]\n",
    "        output = model(inputs)\n",
    "\n",
    "        # Label shape: [batch_size]\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch} Average Loss {average_loss:}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec8cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels, positions, label_positions in test_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs) # , src_mask\n",
    "        \n",
    "        # Apply softmax to convert to probability distribution\n",
    "        probabilities = torch.softmax(outputs, dim=-1)\n",
    "        predicted_labels = probabilities.argmax(dim=-1) # 50, 600\n",
    "        \n",
    "        print(predicted_labels)\n",
    "        print(labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c4872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
