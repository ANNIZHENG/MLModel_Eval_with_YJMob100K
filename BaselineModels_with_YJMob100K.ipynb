{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "642e67f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a45df4",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e9e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "yjmob1 = 'yjmob100k-dataset1.csv.gz' # dataset under normal scenes\n",
    "yjmob_df = pd.read_csv(yjmob1, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15799543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all ids\n",
    "\n",
    "uids = yjmob_df['uid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1803393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to reduce memory space\n",
    "rand_indicies = [random.randint(0, len(uids)) for _ in range(10000)]\n",
    "selected_uids = [uid for uid in uids[rand_indicies]]\n",
    "# selected_uids = uids[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc2f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = yjmob_df[yjmob_df['uid'].isin(selected_uids)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fbfaf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linearization of the 2-dimensional grid, i.e., the original x,y coordinate system\n",
    "def spatial_token(x, y):\n",
    "    # x,y are the coordinate location\n",
    "    # x determines the column order while\n",
    "    # y determines the row order\n",
    "    # (x-1) calculates the starting grid-column position\n",
    "    # (y-1)*200 calculates the start index of the grid-row\n",
    "    return (x-1)+(y-1)*200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e02508b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hx/xp23lpqx4ndfxcvp3qj_bdgr0000gn/T/ipykernel_23395/344338948.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['combined_xy'] = df.apply(lambda row: spatial_token(row['x'], row['y']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "#Location\n",
    "\n",
    "df['combined_xy'] = df.apply(lambda row: spatial_token(row['x'], row['y']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b1ae032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8:2 split\n",
    "\n",
    "train_uids, test_uids = train_test_split(selected_uids, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train = df[df['uid'].isin(train_uids)]\n",
    "df_test = df[df['uid'].isin(test_uids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a172daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01bd08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences(data, data_t):\n",
    "    return torch.tensor(data[:STEP_SIZE]),torch.tensor(data[STEP_SIZE]),\\\n",
    "                torch.tensor(data_t[:STEP_SIZE]),torch.tensor(data_t[STEP_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ee30e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by uid\n",
    "\n",
    "# grouped_data_train = [group for _, group in df_train.groupby('uid')]\n",
    "# grouped_data_test = [group for _, group in df_test.groupby('uid')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb534393",
   "metadata": {},
   "source": [
    "# Rationale behind a model being a 'baseline' model\n",
    "\n",
    "1. No trajectory or sequence of steps awareness\n",
    "2. No timeline awareness (~ Markov Chain, LSTM)\n",
    "3. Memory-less (~ Markov Chain)\n",
    "4. Assume stable and general trajectory for users and at all time (~ somewhat in all models, but not as strong as the two baseline models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9344a49",
   "metadata": {},
   "source": [
    "# Baseline Model 1\n",
    "\n",
    "Average location by time `t`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "888009ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "\n",
    "# all_t = sorted(df_train['t'].unique())\n",
    "all_t = [int(i) for i in range(48)]\n",
    "\n",
    "predictions_by_t = []\n",
    "\n",
    "for t in range(len(all_t)):\n",
    "    loc = list(df_train[df_train['t'] == t]['combined_xy'])\n",
    "    if (len(loc) == 0):\n",
    "        # handle the case when one or more particular t doesn't exist\n",
    "        if (t == 0):\n",
    "            for t in range(t+1, len(all_t)):\n",
    "                loc_next = list(df_train[df_train['t'] == t]['combined_xy'])\n",
    "                if (len(loc_next) > 0):\n",
    "                    predictions_by_t.append(sum(loc_next)/len(loc_next))\n",
    "                    break\n",
    "        else:\n",
    "            predictions_by_t.append(predictions_by_t[-1])\n",
    "    else:\n",
    "        predictions_by_t.append(sum(loc)/len(loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "11e8f3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0, Num Correct: 0, Num Sample: 1982\n"
     ]
    }
   ],
   "source": [
    "## Inferece\n",
    "\n",
    "unique_uid = df_test['uid'].unique()\n",
    "\n",
    "total_correct = 0\n",
    "\n",
    "for usr in unique_uid:\n",
    "    true_label = df_test[df_test['uid']==usr].iloc[[-1]]['combined_xy'].item()\n",
    "    related_time = df_test[df_test['uid']==usr].iloc[[-1]]['t'].item()\n",
    "    total_correct += int(true_label == predictions_by_t[related_time])\n",
    "    \n",
    "print(f\"Accuracy: {total_correct/len(unique_uid)}, Num Correct: {total_correct}, Num Sample: {len(unique_uid)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37df523f",
   "metadata": {},
   "source": [
    "# Baseline Model 2\n",
    "\n",
    "Most frequencly visited location by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8e4f96e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "all_t = [int(i) for i in range(48)]\n",
    "\n",
    "predictions_by_freq = []\n",
    "\n",
    "for t in range(len(all_t)):\n",
    "    loc = list(df_train[df_train['t'] == t]['combined_xy'])\n",
    "    if (len(loc) == 0):\n",
    "        # handle the case when one or more particular t doesn't exist\n",
    "        if (t == 0):\n",
    "            for t in range(t+1, len(all_t)):\n",
    "                loc_next = list(df_train[df_train['t'] == t]['combined_xy'])\n",
    "                if (len(loc_next) > 0):\n",
    "                    most_freq_loc, count = Counter(loc_next).most_common(1)[0]\n",
    "                    predictions_by_freq.append(most_freq_loc)\n",
    "                    break\n",
    "        else:\n",
    "            predictions_by_freq.append(predictions_by_freq[-1])\n",
    "    else:\n",
    "        most_freq_loc , count = Counter(loc).most_common(1)[0]\n",
    "        predictions_by_freq.append(most_freq_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9742ecfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0010090817356205853, Num Correct: 2, Num Sample: 1982\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "\n",
    "# Interesting to see that 15334 is very repetitive, you also see in Transformer that it tends to predict 15334\n",
    "# would the transformer predicting 15334 considered as a kind of overfitting? (check the confidence)\n",
    "\n",
    "unique_uid = df_test['uid'].unique()\n",
    "\n",
    "total_correct = 0\n",
    "\n",
    "for usr in unique_uid:\n",
    "    true_label = df_test[df_test['uid']==usr].iloc[[-1]]['combined_xy'].item()\n",
    "    related_time = df_test[df_test['uid']==usr].iloc[[-1]]['t'].item()\n",
    "    total_correct += int(true_label == predictions_by_freq[related_time])\n",
    "    \n",
    "print(f\"Accuracy: {total_correct/len(unique_uid)}, Num Correct: {total_correct}, Num Sample: {len(unique_uid)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b0189c",
   "metadata": {},
   "source": [
    "# Baseline Model 3\n",
    "\n",
    "Random guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea3cbb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0, Num Correct: 0, Num Sample: 1982\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "\n",
    "unique_uid = df_test['uid'].unique()\n",
    "\n",
    "total_correct = 0\n",
    "\n",
    "for usr in unique_uid:\n",
    "    true_label = df_test[df_test['uid']==usr].iloc[[-1]]['combined_xy'].item()\n",
    "    related_time = df_test[df_test['uid']==usr].iloc[[-1]]['t'].item()\n",
    "    total_correct += int(random.randint(0,40000-1) == predictions_by_freq[related_time])\n",
    "    \n",
    "print(f\"Accuracy: {total_correct/len(unique_uid)}, Num Correct: {total_correct}, Num Sample: {len(unique_uid)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
